{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "## import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sqlalchemy \n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## Add the path of the functions folder\n",
    "current_dir = os.getcwd()  ## Gets the current working directory\n",
    "sub_dir = os.path.abspath(os.path.join(current_dir, '..'\n",
    "                                       , 'Functions'))\n",
    "sys.path.append(sub_dir)\n",
    "\n",
    "# Now you can import functions\n",
    "from db_secrets import SQL_107\n",
    "\n",
    "#from visualisations import plot_prediction_error, plot_prediction_density_subplots\n",
    "\n",
    "from helpers import aggregate_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-survival\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text for query\n",
    "with open(\"../Exploratory_Analysis/111_sql.sql\", \"r\") as file:\n",
    "    query_text = file.read()\n",
    "\n",
    "query_text = query_text.replace('REPLACE START DATE','2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an engine + connection\n",
    "engine = create_engine(SQL_107())\n",
    "conn = engine.connect()\n",
    "\n",
    "## Return data\n",
    "df_raw = pd.read_sql(query_text,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "#df = df.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Call Connect Time'\n",
    "         ,'Outcome Location Name'\n",
    "         ,'Bank Holiday'\n",
    "         , 'In_Out_Hours'\n",
    "         , 'Sub ICB Name'\n",
    "         ,'Outcome Type'\n",
    "         ,'Outcome Datetime']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome'] = df['Outcome Type'].transform(lambda x: False if x == 'No UEC Contact' else True)\n",
    "df = df.drop(['Outcome Type'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Round time to nearest minute\n",
    "df['Call Connect Time'] = df['Call Connect Time'].dt.round(freq='min')\n",
    "df['Outcome Datetime'] = df['Outcome Datetime'].dt.round(freq='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mins to outcome'] = df['Outcome Datetime'] - df['Call Connect Time']\n",
    "df['Mins to outcome'] = df['Mins to outcome'].dt.total_seconds()/60\n",
    "\n",
    "## right censored data upto 24 hours\n",
    "df['Mins to outcome'] = df['Mins to outcome'].fillna(1441) ## minutes in day+1\n",
    "df['Mins to outcome'] = df['Mins to outcome'].transform(lambda x: 1441 if x > 1441 else x) \n",
    "\n",
    "## removes zeros and less than zero\n",
    "df = df[df['Mins to outcome'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replaces low frequency sites with 'OTHER SITE'\n",
    "df['Outcome Location Name'] = (df['Outcome Location Name']\n",
    "                               .apply(lambda x: aggregate_sites(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## groups rare sites for a place\n",
    "positive_counts = df.groupby(['Sub ICB Name', 'Outcome Location Name'])['Outcome'].sum().reset_index(name='Attends')\n",
    "\n",
    "total_positives = positive_counts.groupby('Sub ICB Name')['Attends'].sum().reset_index(name='Total_Attends')\n",
    "\n",
    "lu_site_agg = positive_counts.merge(total_positives, on='Sub ICB Name')\n",
    "lu_site_agg['Percentage'] = (lu_site_agg['Attends'] / lu_site_agg['Total_Attends']) * 100\n",
    "\n",
    "lu_site_agg['Location'] = 'OTHER SITE'\n",
    "\n",
    "## keep details of sites with > 5% of activity\n",
    "lu_site_agg.loc[(lu_site_agg['Percentage'] > 5) &\n",
    "                (lu_site_agg['Outcome Location Name'] != 'No UEC Contact')\n",
    "                , 'Location'] = lu_site_agg['Outcome Location Name']\n",
    "\n",
    "lu_site_agg.loc[lu_site_agg['Outcome Location Name'] == 'No UEC Contact'\n",
    "                , 'Location'] = 'No UEC Contact'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new location\n",
    "df=pd.merge(df\n",
    "         ,lu_site_agg[['Sub ICB Name','Outcome Location Name','Location']]\n",
    "         , on = ['Sub ICB Name','Outcome Location Name']\n",
    "         , how='left')\n",
    "\n",
    "## Drop previous location\n",
    "df = df.drop('Outcome Location Name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date time conversion to numeric\n",
    "df['year']    = df['Call Connect Time'].dt.year\n",
    "\n",
    "df['month sin'] = np.sin(df['Call Connect Time'].dt.month * (2*np.pi/12))\n",
    "df['month cos'] = np.cos(df['Call Connect Time'].dt.month * (2*np.pi/12))\n",
    "\n",
    "df['YearDay sin'] = np.sin(df['Call Connect Time'].dt.day_of_year * (2*np.pi/365))\n",
    "df['YearDay cos'] = np.cos(df['Call Connect Time'].dt.day_of_year * (2*np.pi/365))\n",
    "\n",
    "df['weekday sin'] = np.sin(df['Call Connect Time'].dt.weekday+1 * (2*np.pi/7))  # Monday=0, Sunday=6\n",
    "df['weekday cos'] = np.cos(df['Call Connect Time'].dt.weekday+1 * (2*np.pi/7))  # Monday=0, Sunday=6\n",
    "\n",
    "df['Hour sin'] = np.sin(df['Call Connect Time'].dt.hour * (2*np.pi/24))\n",
    "df['Hour cos'] = np.cos(df['Call Connect Time'].dt.hour * (2*np.pi/24))\n",
    "\n",
    "df = df.drop('Call Connect Time',axis=1) \n",
    "df = df.drop('Outcome Datetime',axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].astype('category')\n",
    "df['Bank Holiday'] = df['Bank Holiday'].astype('category')\n",
    "df['In_Out_Hours'] = df['In_Out_Hours'].astype('category')\n",
    "df['Sub ICB Name'] = df['Sub ICB Name'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_cols = ['Outcome','Mins to outcome']\n",
    "\n",
    "X = df.drop(outcome_cols,axis=1)\n",
    "y = df[outcome_cols]\n",
    "\n",
    "y = np.array(\n",
    "    list(y.itertuples(index=False, name=None)),  # Convert rows to tuples\n",
    "    dtype=[('Outcome', '?'), ('Mins to outcome', '<f8')]  # Define the structured dtype\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    , y \n",
    "                                                    , stratify=y[\"Outcome\"] ## make sure there are equal proportions in test and train\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaplan_meier_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, survival_prob, conf_int = kaplan_meier_estimator(\n",
    "          y_train[\"Outcome\"]\n",
    "        , y_train[\"Mins to outcome\"]\n",
    "        , conf_type=\"log-log\"\n",
    "        )\n",
    "\n",
    "plt.step(time, survival_prob, where=\"post\")\n",
    "plt.fill_between(time, conf_int[0], conf_int[1], alpha=0.25, step=\"post\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(r\"est. probability of not attend UEC $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"minutes $t$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_list = []\n",
    "place_list = df['Sub ICB Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for place in place_list:\n",
    "    mask_place = X_train[\"Sub ICB Name\"] == place\n",
    "    time, survival_prob, conf_int = kaplan_meier_estimator(\n",
    "                                    y_train[\"Outcome\"][mask_place]\n",
    "                                    , y_train[\"Mins to outcome\"][mask_place],\n",
    "                                    conf_type=\"log-log\",\n",
    "                                    )\n",
    "\n",
    "    plt.step(time, survival_prob, where=\"post\", label=f\"Place = {place}\")\n",
    "    plt.fill_between(time, np.nan_to_num(conf_int[0])\n",
    "                        , np.nan_to_num(conf_int[1])\n",
    "                        , alpha=0.25, step=\"post\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(r\"est. probability of not attend UEC $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"minutes $t$\")\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a new df with one copy of the data per site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Outcome_Location = df[ ~df['Location'].isin(\n",
    "                            [ 'No UEC Contact', 'OTHER SITE']) ]['Location'].unique()\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "#for Location in Outcome_Location:\n",
    "for Location in ['UNIVERSITY HOSPITAL OF NORTH DURHAM']:\n",
    "    print(Location)\n",
    "    temp_df = df.copy()\n",
    "    temp_df['Site Version'] = Location\n",
    "    temp_df['Outcome'] = temp_df['Location'] == Location\n",
    "    #temp_df['Mins to outcome'] = np.where(temp_df['Outcome'], temp_df['Mins to outcome'], 1441)\n",
    "\n",
    "    new_df = pd.concat([new_df,temp_df], ignore_index=True, sort=False)\n",
    "\n",
    "new_df['Site Version'] = new_df['Site Version'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_cols = ['Outcome','Mins to outcome']\n",
    "\n",
    "new_X = new_df.drop(outcome_cols,axis=1)\n",
    "new_X = new_X.drop(['Location'],axis=1)\n",
    "new_y = new_df[outcome_cols]\n",
    "\n",
    "new_y = np.array(\n",
    "    list(new_y.itertuples(index=False, name=None)),  # Convert rows to tuples\n",
    "    dtype=[('Outcome', '?'), ('Mins to outcome', '<f8')]  # Define the structured dtype\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X\n",
    "                                                    , new_y \n",
    "                                                    , stratify=new_y[\"Outcome\"] ## make sure there are equal proportions in test and train\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outcome_cols = ['Outcome','Mins to outcome']\n",
    "#\n",
    "#X = df.drop(outcome_cols,axis=1)\n",
    "#y = df[outcome_cols]\n",
    "#\n",
    "#y = np.array(\n",
    "#    list(y.itertuples(index=False, name=None)),  # Convert rows to tuples\n",
    "#    dtype=[('Outcome', '?'), ('Mins to outcome', '<f8')]  # Define the structured dtype\n",
    "#    )\n",
    "#\n",
    "#\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X\n",
    "#                                                    , y \n",
    "#                                                    , stratify=y[\"Outcome\"] ## make sure there are equal proportions in test and train\n",
    "#                                                    , test_size = 0.25\n",
    "#                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cph = make_pipeline(OneHotEncoder(), CoxPHSurvivalAnalysis())\n",
    "#cph.fit(X_train, y_train) ##takes 30+ mins\n",
    "\n",
    "\n",
    "rsf = make_pipeline(OneHotEncoder(), RandomSurvivalForest(n_estimators=100\n",
    "                                                          , min_samples_leaf=7\n",
    "                                                          , random_state=42\n",
    "                                                          ,low_memory=False))\n",
    "rsf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_windows = np.arange(20, 241, 5)\n",
    "\n",
    "rsf_chf_funcs = rsf.predict_cumulative_hazard_function(X_test, return_array=False)\n",
    "rsf_risk_scores = np.vstack([chf(arrival_windows) for chf in rsf_chf_funcs])\n",
    "\n",
    "rsf_auc, rsf_mean_auc = cumulative_dynamic_auc(y_train, y_test, rsf_risk_scores, arrival_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_risk_scores = cph.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_windows = np.arange(20, 241, 5)\n",
    "cph_auc, cph_mean_auc = cumulative_dynamic_auc(y_train\n",
    "                                               , y_test\n",
    "                                               , cph_risk_scores\n",
    "                                               , arrival_windows)\n",
    "\n",
    "plt.plot(arrival_windows, cph_auc, marker=\"o\")\n",
    "plt.axhline(cph_mean_auc, linestyle=\"--\")\n",
    "plt.xlabel(\"minutes from call\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.nonparametric import CensoringDistributionEstimator\n",
    "\n",
    "# Fit the censoring distribution estimator\n",
    "cens = CensoringDistributionEstimator()\n",
    "cens.fit(y_train)\n",
    "\n",
    "# Predict censoring probabilities for arrival windows\n",
    "censoring_probs = cens.predict_proba(arrival_windows)\n",
    "\n",
    "# Print problematic time points\n",
    "print(\"Censoring survival probabilities:\", censoring_probs)\n",
    "print(\"Arrival windows with zero censoring survival function:\", arrival_windows[censoring_probs == 0])\n",
    "\n",
    "# Filter out invalid time points\n",
    "valid_times = arrival_windows[censoring_probs > 0]\n",
    "\n",
    "# Recompute AUC with valid time points\n",
    "cph_auc, cph_mean_auc = cumulative_dynamic_auc(y_train, y_test, cph_risk_scores, valid_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import load_veterans_lung_cancer\n",
    "va_x, va_y = load_veterans_lung_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "va_x, va_y = load_veterans_lung_cancer()\n",
    "\n",
    "va_x_train, va_x_test, va_y_train, va_y_test = train_test_split(\n",
    "    va_x, va_y, test_size=0.2, stratify=va_y[\"Status\"], random_state=0\n",
    ")\n",
    "\n",
    "va_cph = make_pipeline(OneHotEncoder(), CoxPHSurvivalAnalysis())\n",
    "va_cph.fit(va_x_train, va_y_train)\n",
    "\n",
    "va_times = np.arange(8, 184, 7)\n",
    "va_cph_risk_scores = va_cph.predict(va_x_test)\n",
    "va_cph_auc, va_cph_mean_auc = cumulative_dynamic_auc(va_y_train, va_y_test, va_cph_risk_scores, va_times)\n",
    "\n",
    "plt.plot(va_times, va_cph_auc, marker=\"o\")\n",
    "plt.axhline(va_cph_mean_auc, linestyle=\"--\")\n",
    "plt.xlabel(\"days from enrollment\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_cph_risk_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
