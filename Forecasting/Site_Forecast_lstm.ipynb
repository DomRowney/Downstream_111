{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from itertools import product\n",
    "## import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sqlalchemy \n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## Add the path of the functions folder\n",
    "current_dir = os.getcwd()  ## Gets the current working directory\n",
    "sub_dir = os.path.abspath(os.path.join(current_dir, '..'\n",
    "                                       , 'Functions'))\n",
    "sys.path.append(sub_dir)\n",
    "\n",
    "# Now you can import functions\n",
    "from db_secrets import SQL_107\n",
    "\n",
    "from visualisations import plot_prediction_error, plot_prediction_density_subplots\n",
    "\n",
    "from helpers import aggregate_sites, keras_calculate_accuracy, keras_calculate_baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow sequential model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Concatenate, LSTM, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text for query\n",
    "with open(\"../Exploratory_Analysis/111_sql.sql\", \"r\") as file:\n",
    "    query_text = file.read()\n",
    "\n",
    "query_text = query_text.replace('REPLACE START DATE','2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an engine + connection\n",
    "engine = create_engine(SQL_107())\n",
    "conn = engine.connect()\n",
    "\n",
    "## Return data\n",
    "df_raw = pd.read_sql(query_text,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "#df = df.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Start_Location', 'Call ID', 'Pseudo NHS Number', 'CallDate',\n",
       "       'Call Connect Time', 'Weekday_Name', 'Week_Start', 'Financial Year',\n",
       "       'Bank Holiday', 'In_Out_Hours', 'Sub ICB Code', 'Sub ICB Name',\n",
       "       'GP Practice', 'GP Practice Code', 'GP Deprivation',\n",
       "       'GP Survey Q21 Wait for Appt', 'Symptom_Group',\n",
       "       'Final Disposition Code', 'Disposition Group', 'Disposition',\n",
       "       'Call_Taker_Triages', 'Clinical_Triages', 'Patient Age', 'Patient Sex',\n",
       "       'Outcome ID', 'Outcome Datetime', 'Outcome Type', 'Outcome',\n",
       "       'Outcome Location Code', 'Outcome Location Name', 'Hours to Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## List columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Call Connect Time'\n",
    "         ,'Outcome Location Name'\n",
    "         ,'Bank Holiday'\n",
    "         , 'In_Out_Hours'\n",
    "         , 'Sub ICB Name'\n",
    "         ,'Outcome Type']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Round time to nearest hour\n",
    "df['Call Connect Time'] = df['Call Connect Time'].dt.round(freq='h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replaces low frequency sites with 'OTHER SITE'\n",
    "df['Outcome Location Name'] = (df['Outcome Location Name']\n",
    "                               .apply(lambda x: aggregate_sites(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th>Outcome Location Name</th>\n",
       "      <th>Bank Holiday</th>\n",
       "      <th>In_Out_Hours</th>\n",
       "      <th>Sub ICB Name</th>\n",
       "      <th>Outcome Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>No UEC Contact</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>Tees Valley</td>\n",
       "      <td>No UEC Contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-05 00:00:00</td>\n",
       "      <td>No UEC Contact</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>Newcastle Gateshead</td>\n",
       "      <td>No UEC Contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>No UEC Contact</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>Tees Valley</td>\n",
       "      <td>No UEC Contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>No UEC Contact</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>Newcastle Gateshead</td>\n",
       "      <td>No UEC Contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05 02:00:00</td>\n",
       "      <td>No UEC Contact</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>Newcastle Gateshead</td>\n",
       "      <td>No UEC Contact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Call Connect Time Outcome Location Name Bank Holiday  In_Out_Hours  \\\n",
       "0 2022-01-05 01:00:00        No UEC Contact           No  Out of Hours   \n",
       "1 2022-01-05 00:00:00        No UEC Contact           No  Out of Hours   \n",
       "2 2022-01-05 01:00:00        No UEC Contact           No  Out of Hours   \n",
       "3 2022-01-05 01:00:00        No UEC Contact           No  Out of Hours   \n",
       "4 2022-01-05 02:00:00        No UEC Contact           No  Out of Hours   \n",
       "\n",
       "          Sub ICB Name    Outcome Type  \n",
       "0          Tees Valley  No UEC Contact  \n",
       "1  Newcastle Gateshead  No UEC Contact  \n",
       "2          Tees Valley  No UEC Contact  \n",
       "3  Newcastle Gateshead  No UEC Contact  \n",
       "4  Newcastle Gateshead  No UEC Contact  "
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Calls'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome'] = df['Outcome Type'].transform(lambda x: 0 if x == 'No UEC Contact' else 1)\n",
    "df = df.drop(['Outcome Type'],axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reassemble data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregates to one column per place per timestamp\n",
    "df_call = pd.pivot_table(df\n",
    "                        ,values = 'Calls'\n",
    "                        ,index = 'Call Connect Time'\n",
    "                        ,columns ='Sub ICB Name'\n",
    "                        ,aggfunc ='sum'\n",
    "                        ,fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sub ICB Name</th>\n",
       "      <th>County Durham</th>\n",
       "      <th>Newcastle Gateshead</th>\n",
       "      <th>North Tyneside</th>\n",
       "      <th>Northumberland</th>\n",
       "      <th>South Tyneside</th>\n",
       "      <th>Sunderland</th>\n",
       "      <th>Tees Valley</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sub ICB Name         County Durham  Newcastle Gateshead  North Tyneside  \\\n",
       "Call Connect Time                                                         \n",
       "2022-01-01 00:00:00              3                    4               1   \n",
       "2022-01-01 01:00:00              8                    5               0   \n",
       "2022-01-01 02:00:00              4                    3               5   \n",
       "2022-01-01 03:00:00              3                    4               3   \n",
       "2022-01-01 04:00:00              2                    2               1   \n",
       "\n",
       "Sub ICB Name         Northumberland  South Tyneside  Sunderland  Tees Valley  \n",
       "Call Connect Time                                                             \n",
       "2022-01-01 00:00:00               4               0           1            6  \n",
       "2022-01-01 01:00:00               5               1           3            2  \n",
       "2022-01-01 02:00:00               5               1           2            2  \n",
       "2022-01-01 03:00:00               4               1           0            7  \n",
       "2022-01-01 04:00:00               3               0           0            5  "
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_call.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site = df[df['Outcome']==1]\n",
    "\n",
    "df_site = df_site[[ 'Call Connect Time'\n",
    "         , 'Outcome Location Name'\n",
    "         , 'Outcome'\n",
    "         ,]].groupby([ pd.Grouper(key='Call Connect Time', freq='1h')\n",
    "         , 'Outcome Location Name']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removes OTHER SITE\n",
    "df_site = df_site[~(df_site['Outcome Location Name']=='OTHER SITE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th>Outcome Location Name</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>QUEEN ELIZABETH HOSPITAL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>SUNDERLAND ROYAL HOSPITAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH DURHAM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH TEES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Call Connect Time                           Outcome Location Name  Outcome\n",
       "0        2022-01-01  NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL        1\n",
       "1        2022-01-01                        QUEEN ELIZABETH HOSPITAL        2\n",
       "2        2022-01-01                       SUNDERLAND ROYAL HOSPITAL        1\n",
       "3        2022-01-01             UNIVERSITY HOSPITAL OF NORTH DURHAM        1\n",
       "4        2022-01-01               UNIVERSITY HOSPITAL OF NORTH TEES        1"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_site.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times = df[['Call Connect Time'\n",
    "            ,'Bank Holiday'\n",
    "            , 'In_Out_Hours']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th>Bank Holiday</th>\n",
       "      <th>In_Out_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-05 00:00:00</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05 02:00:00</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-05 03:00:00</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-01-05 04:00:00</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Call Connect Time Bank Holiday  In_Out_Hours\n",
       "0  2022-01-05 01:00:00           No  Out of Hours\n",
       "1  2022-01-05 00:00:00           No  Out of Hours\n",
       "4  2022-01-05 02:00:00           No  Out of Hours\n",
       "8  2022-01-05 03:00:00           No  Out of Hours\n",
       "16 2022-01-05 04:00:00           No  Out of Hours"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique timestamps and sites\n",
    "unique_timestamps = df['Call Connect Time'].unique()\n",
    "unique_sites = df_site['Outcome Location Name'].unique()\n",
    "\n",
    "# Create a complete cross join of every site with every timestamp\n",
    "complete_index = pd.DataFrame(product(unique_timestamps, unique_sites)\n",
    "                              , columns=['Call Connect Time'\n",
    "                                         , 'Outcome Location Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge time features\n",
    "df = complete_index.merge(df_times, on='Call Connect Time', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge calls + places\n",
    "df = df.merge(df_call,on='Call Connect Time', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge sites\n",
    "df = df.merge(df_site,on=['Call Connect Time'\n",
    "                           , 'Outcome Location Name'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th>Outcome Location Name</th>\n",
       "      <th>Bank Holiday</th>\n",
       "      <th>In_Out_Hours</th>\n",
       "      <th>County Durham</th>\n",
       "      <th>Newcastle Gateshead</th>\n",
       "      <th>North Tyneside</th>\n",
       "      <th>Northumberland</th>\n",
       "      <th>South Tyneside</th>\n",
       "      <th>Sunderland</th>\n",
       "      <th>Tees Valley</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>QUEEN ELIZABETH HOSPITAL</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>SUNDERLAND ROYAL HOSPITAL</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH DURHAM</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH TEES</td>\n",
       "      <td>No</td>\n",
       "      <td>Out of Hours</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Call Connect Time                           Outcome Location Name  \\\n",
       "0 2022-01-05 01:00:00  NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL   \n",
       "1 2022-01-05 01:00:00                        QUEEN ELIZABETH HOSPITAL   \n",
       "2 2022-01-05 01:00:00                       SUNDERLAND ROYAL HOSPITAL   \n",
       "3 2022-01-05 01:00:00             UNIVERSITY HOSPITAL OF NORTH DURHAM   \n",
       "4 2022-01-05 01:00:00               UNIVERSITY HOSPITAL OF NORTH TEES   \n",
       "\n",
       "  Bank Holiday  In_Out_Hours  County Durham  Newcastle Gateshead  \\\n",
       "0           No  Out of Hours              5                    5   \n",
       "1           No  Out of Hours              5                    5   \n",
       "2           No  Out of Hours              5                    5   \n",
       "3           No  Out of Hours              5                    5   \n",
       "4           No  Out of Hours              5                    5   \n",
       "\n",
       "   North Tyneside  Northumberland  South Tyneside  Sunderland  Tees Valley  \\\n",
       "0               2               1               0           5           11   \n",
       "1               2               1               0           5           11   \n",
       "2               2               1               0           5           11   \n",
       "3               2               1               0           5           11   \n",
       "4               2               1               0           5           11   \n",
       "\n",
       "   Outcome  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      3.0  \n",
       "3      0.0  \n",
       "4      2.0  "
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date time conversion to numeric\n",
    "df['year']    = df['Call Connect Time'].dt.year\n",
    "\n",
    "df['month sin'] = np.sin(df['Call Connect Time'].dt.month * (2*np.pi/12))\n",
    "df['month cos'] = np.cos(df['Call Connect Time'].dt.month * (2*np.pi/12))\n",
    "\n",
    "df['YearDay sin'] = np.sin(df['Call Connect Time'].dt.day_of_year * (2*np.pi/365))\n",
    "df['YearDay cos'] = np.cos(df['Call Connect Time'].dt.day_of_year * (2*np.pi/365))\n",
    "\n",
    "df['weekday sin'] = np.sin(df['Call Connect Time'].dt.weekday+1 * (2*np.pi/7))  # Monday=0, Sunday=6\n",
    "df['weekday cos'] = np.cos(df['Call Connect Time'].dt.weekday+1 * (2*np.pi/7))  # Monday=0, Sunday=6\n",
    "\n",
    "df['Hour sin'] = np.sin(df['Call Connect Time'].dt.hour * (2*np.pi/24))\n",
    "df['Hour cos'] = np.cos(df['Call Connect Time'].dt.hour * (2*np.pi/24))\n",
    "\n",
    "#df = df.drop('Call Connect Time',axis=1) \n",
    "\n",
    "df = df.set_index('Call Connect Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encodinng for boolean variables\n",
    "bool_mapping = {\n",
    "    'Yes': 1,\n",
    "    'No': 0,\n",
    "    'In Hours': 1,\n",
    "    'Out of Hours': 0\n",
    "}\n",
    "\n",
    "df.loc[:,'Is Bank Holiday'] = df['Bank Holiday'].map(bool_mapping)             \n",
    "df.loc[:,'In Hours'] = df['In_Out_Hours'].map(bool_mapping)\n",
    "df = df.drop(['Bank Holiday','In_Out_Hours'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy variables from Outcome Location Name\t\n",
    "#df = pd.concat([df, pd.get_dummies(df['Outcome Location Name']\n",
    "#                                   ,dtype=int\n",
    "#                                   , prefix='Site')]\n",
    "#                ,axis=1)\n",
    "#df = df.drop('Outcome Location Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome Location Name</th>\n",
       "      <th>County Durham</th>\n",
       "      <th>Newcastle Gateshead</th>\n",
       "      <th>North Tyneside</th>\n",
       "      <th>Northumberland</th>\n",
       "      <th>South Tyneside</th>\n",
       "      <th>Sunderland</th>\n",
       "      <th>Tees Valley</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>year</th>\n",
       "      <th>month sin</th>\n",
       "      <th>month cos</th>\n",
       "      <th>YearDay sin</th>\n",
       "      <th>YearDay cos</th>\n",
       "      <th>weekday sin</th>\n",
       "      <th>weekday cos</th>\n",
       "      <th>Hour sin</th>\n",
       "      <th>Hour cos</th>\n",
       "      <th>Is Bank Holiday</th>\n",
       "      <th>In Hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Call Connect Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-05 01:00:00</th>\n",
       "      <td>NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>-0.970381</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 01:00:00</th>\n",
       "      <td>QUEEN ELIZABETH HOSPITAL</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>-0.970381</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 01:00:00</th>\n",
       "      <td>SUNDERLAND ROYAL HOSPITAL</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>-0.970381</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 01:00:00</th>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH DURHAM</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>-0.970381</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 01:00:00</th>\n",
       "      <td>UNIVERSITY HOSPITAL OF NORTH TEES</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>-0.970381</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Outcome Location Name  \\\n",
       "Call Connect Time                                                     \n",
       "2022-01-05 01:00:00  NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL   \n",
       "2022-01-05 01:00:00                        QUEEN ELIZABETH HOSPITAL   \n",
       "2022-01-05 01:00:00                       SUNDERLAND ROYAL HOSPITAL   \n",
       "2022-01-05 01:00:00             UNIVERSITY HOSPITAL OF NORTH DURHAM   \n",
       "2022-01-05 01:00:00               UNIVERSITY HOSPITAL OF NORTH TEES   \n",
       "\n",
       "                     County Durham  Newcastle Gateshead  North Tyneside  \\\n",
       "Call Connect Time                                                         \n",
       "2022-01-05 01:00:00              5                    5               2   \n",
       "2022-01-05 01:00:00              5                    5               2   \n",
       "2022-01-05 01:00:00              5                    5               2   \n",
       "2022-01-05 01:00:00              5                    5               2   \n",
       "2022-01-05 01:00:00              5                    5               2   \n",
       "\n",
       "                     Northumberland  South Tyneside  Sunderland  Tees Valley  \\\n",
       "Call Connect Time                                                              \n",
       "2022-01-05 01:00:00               1               0           5           11   \n",
       "2022-01-05 01:00:00               1               0           5           11   \n",
       "2022-01-05 01:00:00               1               0           5           11   \n",
       "2022-01-05 01:00:00               1               0           5           11   \n",
       "2022-01-05 01:00:00               1               0           5           11   \n",
       "\n",
       "                     Outcome  year  month sin  month cos  YearDay sin  \\\n",
       "Call Connect Time                                                       \n",
       "2022-01-05 01:00:00      0.0  2022        0.5   0.866025     0.085965   \n",
       "2022-01-05 01:00:00      0.0  2022        0.5   0.866025     0.085965   \n",
       "2022-01-05 01:00:00      3.0  2022        0.5   0.866025     0.085965   \n",
       "2022-01-05 01:00:00      0.0  2022        0.5   0.866025     0.085965   \n",
       "2022-01-05 01:00:00      2.0  2022        0.5   0.866025     0.085965   \n",
       "\n",
       "                     YearDay cos  weekday sin  weekday cos  Hour sin  \\\n",
       "Call Connect Time                                                      \n",
       "2022-01-05 01:00:00     0.996298     0.241581    -0.970381  0.258819   \n",
       "2022-01-05 01:00:00     0.996298     0.241581    -0.970381  0.258819   \n",
       "2022-01-05 01:00:00     0.996298     0.241581    -0.970381  0.258819   \n",
       "2022-01-05 01:00:00     0.996298     0.241581    -0.970381  0.258819   \n",
       "2022-01-05 01:00:00     0.996298     0.241581    -0.970381  0.258819   \n",
       "\n",
       "                     Hour cos  Is Bank Holiday  In Hours  \n",
       "Call Connect Time                                         \n",
       "2022-01-05 01:00:00  0.965926                0         0  \n",
       "2022-01-05 01:00:00  0.965926                0         0  \n",
       "2022-01-05 01:00:00  0.965926                0         0  \n",
       "2022-01-05 01:00:00  0.965926                0         0  \n",
       "2022-01-05 01:00:00  0.965926                0         0  "
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outcome Location Name', 'County Durham', 'Newcastle Gateshead',\n",
       "       'North Tyneside', 'Northumberland', 'South Tyneside', 'Sunderland',\n",
       "       'Tees Valley', 'Outcome', 'year', 'month sin', 'month cos',\n",
       "       'YearDay sin', 'YearDay cos', 'weekday sin', 'weekday cos', 'Hour sin',\n",
       "       'Hour cos', 'Is Bank Holiday', 'In Hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_X = df.drop('Outcome',axis=1)# X = all  except the 'Outcome' column\n",
    "base_y = df['Outcome']# y = 'Outcome' column \n",
    "\n",
    "base_X_train, base_X_test, base_y_train, base_y_test = train_test_split(base_X\n",
    "                                                    , base_y \n",
    "                                                    , test_size = 0.25\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joins outcome onto predictors\n",
    "base_df = pd.concat([base_X_train,base_y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns we care about for baseline model\n",
    "group_cols = [\n",
    "    'month sin'\n",
    "    ,'month cos'    \n",
    "    ,'weekday sin'\n",
    "    ,'weekday cos'\n",
    "    ,'Hour sin'\n",
    "    ,'Hour cos'] + df.columns[df.columns.str.startswith('Site_')].to_list() ## sites\n",
    "\n",
    "## Mean value across baseline\n",
    "base_trained = (base_df[group_cols + ['Outcome']]\n",
    "                .groupby(group_cols)\n",
    "                .agg( Pred_Outcome=pd.NamedAgg(column=\"Outcome\"\n",
    "                                               , aggfunc=\"mean\"))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_y_pred_train = pd.merge(base_X_train,base_trained,how='left',on=group_cols)['Pred_Outcome']\n",
    "base_y_pred_test = pd.merge(base_X_test,base_trained,how='left',on=group_cols)['Pred_Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_data(df,col,one_hot=False,lags=[1,2,3,4,12,24,168]):\n",
    "    \"\"\"calcultes the lags for a dataframe column\"\"\"\n",
    "    \n",
    "    print(f' > Calculating lags for: {col}')\n",
    "    \n",
    "    lagged_features = pd.DataFrame()\n",
    "\n",
    "    for x in lags:\n",
    "        # Create lag features\n",
    "        lagged_features[f'{col}_Lag{x}'] = df[col].shift(x)  # Previous x\n",
    "        if one_hot & (x > 1):\n",
    "            # Calculate rolling statistics\n",
    "            lagged_features[f'{col}_mean{x}'] = df[col].rolling(window=x).mean()\n",
    "            lagged_features[f'{col}_STD{x}']  = df[col].rolling(window=x).std() \n",
    "            lagged_features[f'{col}_min{x}']  = df[col].rolling(window=x).min() \n",
    "            lagged_features[f'{col}_max{x}']  = df[col].rolling(window=x).max() \n",
    "            lagged_features[f'{col}_median{x}']  = df[col].rolling(window=x).median()\n",
    "            lagged_features[f'{col}_var{x}']  = df[col].rolling(window=x).var()\n",
    "\n",
    "    df = pd.concat([df, lagged_features], axis=1)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Calculating lags for: Outcome\n",
      " > Calculating lags for: County Durham\n",
      " > Calculating lags for: Newcastle Gateshead\n",
      " > Calculating lags for: North Tyneside\n",
      " > Calculating lags for: Northumberland\n",
      " > Calculating lags for: South Tyneside\n",
      " > Calculating lags for: Sunderland\n",
      " > Calculating lags for: Tees Valley\n",
      " > Calculating lags for: Is Bank Holiday\n",
      " > Calculating lags for: In Hours\n"
     ]
    }
   ],
   "source": [
    "cols_to_lag = ['Outcome']\n",
    "cols_to_lag.extend(list(df_call.columns))\n",
    "\n",
    "for col in cols_to_lag:\n",
    "    df = lag_data(df,col,one_hot=True)\n",
    "\n",
    "one_hot_cols_to_lag = ['Is Bank Holiday', 'In Hours']\n",
    "\n",
    "for col in one_hot_cols_to_lag:\n",
    "    df = lag_data(df,col,one_hot=False)\n",
    "\n",
    "df = df[168:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['Outcome Location Name'] == 'NORTHUMBRIA SPECIALIST EMERGENCY CARE HOSPITAL']\n",
    "#df = df.drop('Outcome Location Name',axis=1)\n",
    "columns_order = (['Outcome'] + \n",
    "                 ['Outcome Location Name'] + \n",
    "                 [col for col in df.columns if col not in  ['Outcome','Outcome Location Name']] )\n",
    "df = df[columns_order]\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "test_train_split = 0.70\n",
    "train_size = int(len(df) * test_train_split)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test):\n",
    "    \"\"\"Scale data 0-1 based on min and max in training set\n",
    "        , excluding the first and second column\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = MinMaxScaler()\n",
    "    \n",
    "    # Select columns to scale\n",
    "    train_to_scale = train.iloc[:, 2:]\n",
    "    test_to_scale = test.iloc[:, 2:]\n",
    "    \n",
    "    # Apply the scaler to the selected columns\n",
    "    train_sc = sc.fit_transform(train_to_scale)\n",
    "    test_sc = sc.transform(test_to_scale)\n",
    "    \n",
    "    # Combine the unscaled first column with the scaled remaining columns\n",
    "    train_result = pd.concat([\n",
    "        train.iloc[:, :2],  # Unscaled columns\n",
    "        pd.DataFrame(train_sc, columns=train_to_scale.columns\n",
    "                     , index=train.index)  # Scaled columns\n",
    "    ], axis=1)\n",
    "    \n",
    "    test_result = pd.concat([\n",
    "        test.iloc[:, :2],  # Unscaled columns\n",
    "        pd.DataFrame(test_sc, columns=test_to_scale.columns\n",
    "                     , index=test.index)  # Scaled columns\n",
    "    ], axis=1)\n",
    "    \n",
    "    return train_result, test_result, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X data\n",
    "train_df_sc, test_df_sc,scaler  = scale_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ids = df['Outcome Location Name'].values\n",
    "unique_series = df['Outcome Location Name'].unique()\n",
    "series_map = {s: i for i, s in enumerate(unique_series)}\n",
    "series_ids_encoded = np.array([series_map[s] for s in series_ids])\n",
    "\n",
    "series_one_hot = to_categorical(series_ids_encoded\n",
    "                                    , num_classes=len(unique_series))\n",
    "\n",
    "t = df.iloc[:,list(range(1,df.shape[1]))].values\n",
    "t = np.hstack([t, series_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windowed(df                 \n",
    "                  ,window_length = 24*8\n",
    "                  ,batch_size = 256\n",
    "                  ,series_col = 'Outcome Location Name'):\n",
    "    \n",
    "    # Separate the series ID\n",
    "    series_ids = df[series_col].values\n",
    "    \n",
    "    # One-hot encode series IDs\n",
    "    unique_series = df[series_col].unique()\n",
    "    series_map = {s: i for i, s in enumerate(unique_series)}\n",
    "    series_ids_encoded = np.array([series_map[s] for s in series_ids])\n",
    "    series_one_hot = to_categorical(series_ids_encoded\n",
    "                                    , num_classes=len(unique_series))\n",
    "\n",
    "    # Separate features (X) and targets (y)\n",
    "    X = df.iloc[:,2:df.shape[1] ].values\n",
    "    X = np.hstack([X, series_one_hot])\n",
    "    y = df.iloc[:,[0]]\n",
    "\n",
    "    dataset = timeseries_dataset_from_array(\n",
    "        data=X,\n",
    "        targets=y,\n",
    "        sequence_length=window_length, \n",
    "        sampling_rate=1, #skip items\n",
    "        batch_size=batch_size, #group together sequences efficiently in memory\n",
    "    )\n",
    "\n",
    "    return dataset, len(unique_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 24*8\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset, train_sites_N = make_windowed(train_df_sc,window_length,batch_size,series_col = 'Outcome Location Name')\n",
    "test_dataset, test_sites_N  = make_windowed(test_df_sc,window_length,batch_size,series_col = 'Outcome Location Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(None, None, None, 388), dtype=tf.float64, name=None)"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.batch(32)._structure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(window_length,\n",
    "            number_features, \n",
    "            number_series,\n",
    "            hidden_layers=1, \n",
    "            lstm_units=64,\n",
    "            hidden_layer_neurones=128, \n",
    "            dropout=0.0, \n",
    "            learning_rate=0.003):\n",
    "    \n",
    "    \"\"\"Make TensorFlow neural net\"\"\"\n",
    "    \n",
    "    # Clear Tensorflow \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Set up neural net\n",
    "    net = Sequential()\n",
    "\n",
    "    # input shape\n",
    "    net.add(InputLayer((window_length,number_features + number_series)))\n",
    "\n",
    "    # LSTM\n",
    "    net.add(LSTM(lstm_units,return_sequences = True))\n",
    "    net.add(LSTM(int(lstm_units/2)))\n",
    "\n",
    "    # Add hidden hidden_layers using a loop\n",
    "    for i in range(hidden_layers):\n",
    "        # Add fully connected layer with ReLu activation\n",
    "        net.add(Dense(\n",
    "            hidden_layer_neurones, \n",
    "            input_dim=number_features,\n",
    "            activation='relu'))\n",
    "        # Add droput layer\n",
    "        net.add(Dropout(dropout))\n",
    "    \n",
    "    # Add final sigmoid activation output\n",
    "    net.add(Dense(number_series, activation='linear'))    \n",
    "    #    net.add(Dense(1, activation='sigmoid'))    \n",
    "\n",
    "    # Compiling model\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    net.compile(loss='mse', \n",
    "                optimizer=opt, \n",
    "                metrics=['mse','mae'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (256, 192, 388) | batch size=256, sequence length=192, features=388\n",
      "y (256, 1) | batch size=256, outcomes=1\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataset.take(1): #takes 1 batch\n",
    "    print(f'X {X_batch.shape} | batch size={X_batch.shape[0]}, sequence length={X_batch.shape[1]}, features={X_batch.shape[2]}')\n",
    "    print(f'y {y_batch.shape} | batch size={y_batch.shape[0]}, outcomes={y_batch.shape[1]}')\n",
    "\n",
    "    number_features = X_batch.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_net(window_length = window_length,\n",
    "             number_features=number_features, \n",
    "             number_series=train_sites_N,\n",
    "             lstm_units = 128,\n",
    "             hidden_layers=1, \n",
    "             hidden_layer_neurones=128, \n",
    "             dropout=0.01, \n",
    "             learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">270,848</span> \n",
       "\n",
       " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m270,848\u001b[0m \n",
       "\n",
       " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m49,408\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m8,320\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                      \u001b[38;5;34m1,548\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">330,124</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m330,124\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">330,124</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m330,124\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 388 and 400 for '{{node sequential_1/lstm_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_1/lstm_1/strided_slice_4, sequential_1/lstm_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [?,388], [400,512].\u001b[0m\n\nArguments received by LSTMCell.call():\n   inputs=tf.Tensor(shape=(None, 388), dtype=float32)\n   states=('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)')\n   training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[802], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m early_stopping_cb_loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m      9\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Train model (and store training info in history)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_dataset,\n\u001b[0;32m     13\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     14\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     15\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[0;32m     16\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     17\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_cb\n\u001b[0;32m     18\u001b[0m                                , early_stopping_cb_loss\n\u001b[0;32m     19\u001b[0m                                ])\n",
      "File \u001b[1;32mc:\\Users\\dominic.rowney\\AppData\\Local\\anaconda3\\envs\\downstream_111\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\dominic.rowney\\AppData\\Local\\anaconda3\\envs\\downstream_111\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 388 and 400 for '{{node sequential_1/lstm_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_1/lstm_1/strided_slice_4, sequential_1/lstm_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [?,388], [400,512].\u001b[0m\n\nArguments received by LSTMCell.call():\n   inputs=tf.Tensor(shape=(None, 388), dtype=float32)\n   states=('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)')\n   training=True"
     ]
    }
   ],
   "source": [
    "# Define save checkpoint callback (only save if new best validation results)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'model_checkpoint.keras', save_best_only=True)\n",
    "\n",
    "# Define early stopping callback\n",
    "# Stop when no validation improvement for 25 epochs\n",
    "# Restore weights to best validation accuracy\n",
    "early_stopping_cb_loss = keras.callbacks.EarlyStopping(\n",
    "    patience=25, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "### Train model (and store training info in history)\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint_cb\n",
    "                               , early_stopping_cb_loss\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get predictions\n",
    "test_predictions = model.predict(test_dataset).flatten()\n",
    "test_predictions = pd.DataFrame(data={'Predict':test_predictions})\n",
    "\n",
    "## get actuals\n",
    "test_actuals = test_df_sc.iloc[:len(test_predictions), [0]]\n",
    "test_actuals.sort_index(inplace=True)\n",
    "test_actuals['Mean']  = test_actuals['Outcome'].mean()\n",
    "\n",
    "## combine into dataframe\n",
    "test_predictions = pd.concat([\n",
    "        test_actuals, \n",
    "        test_predictions.set_index(test_actuals.index)\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot a sample of actual against predicted\n",
    "minplot = 1000\n",
    "maxplot = 1100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_predictions['Outcome'][minplot:maxplot], label=\"Actual\")\n",
    "plt.plot(test_predictions['Predict'][minplot:maxplot], label=\"Prediction\")\n",
    "plt.plot(test_predictions['Mean'][minplot:maxplot], label=\"Mean Actual\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Add title and axis labels for context\n",
    "plt.title(\"TensorFlow LSTM: Predictions vs Actuals\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, future, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    future = list(range(future_steps))\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i == 0:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "        else:            \n",
    "            plt.plot(future, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "future_steps = 24\n",
    "for x, y in test_dataset.take(5):\n",
    "    show_plot(\n",
    "        #[x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        #1,\n",
    "        [x[0][:, 1].numpy(),\n",
    "          y[0].numpy()[:future_steps],\n",
    "            model.predict(x)[0][:future_steps]],\n",
    "        future_steps,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGACY BEYOND HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxx STOP xxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_site_accuracy(df,model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Calculate and print accuracy at site level of training and test data fits\"\"\"    \n",
    "    \n",
    "    X_df = df.drop('Outcome',axis=1)\n",
    "    site_columns = X_df.columns[X_df.columns.str.startswith('Site_')]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for site in site_columns:\n",
    "        \n",
    "        # Get the column index for the site\n",
    "        site_idx = X_df.columns.get_loc(site)\n",
    "\n",
    "        # Filter array where site column equals 1\n",
    "        test_index = np.where(X_test[:, site_idx] == 1)[0]  \n",
    "        site_X_test = X_test[test_index]\n",
    "        site_y_test = y_test[test_index]\n",
    "\n",
    "        train_index = np.where(X_train[:, site_idx] == 1)[0]  \n",
    "        site_X_train = X_train[train_index]\n",
    "        site_y_train = y_train[train_index]\n",
    "\n",
    "        # Predict on training and test data\n",
    "        print(f'{site}: col {site_idx}')\n",
    "        site_y_pred_train = model.predict(site_X_train).flatten()\n",
    "        site_y_pred_test = model.predict(site_X_test).flatten()\n",
    "    \n",
    "        # Calculate Mean Absolute Error (MAE) for training and test sets\n",
    "        site_mae_train = np.mean(np.abs(site_y_pred_train - site_y_train))\n",
    "        site_mae_test = np.mean(np.abs(site_y_pred_test - site_y_test))\n",
    "        \n",
    "        # Calculate Mean Squared Error (MSE) for training and test sets\n",
    "        site_mse_train = np.mean((site_y_pred_train - site_y_train) ** 2)\n",
    "        site_mse_test = np.mean((site_y_pred_test - site_y_test) ** 2)\n",
    "\n",
    "        # Calculate Root Mean Squared Error (RMSE) for training and test sets\n",
    "        site_rmse_train = np.sqrt(site_mse_train)\n",
    "        site_rmse_test = np.sqrt(site_mse_test)\n",
    "\n",
    "        # Calculate NRMSE (Normalized RMSE)\n",
    "        range_y_train = np.max(site_y_train) - np.min(site_y_train)  # Range of y_train\n",
    "        range_y_test = np.max(site_y_test) - np.min(site_y_test)  # Range of y_test\n",
    "        site_nrmse_train = site_rmse_train / range_y_train\n",
    "        site_nrmse_test = site_rmse_test / range_y_test\n",
    "\n",
    "        # Calculate R^2 for training and test sets\n",
    "        ss_total_train = np.sum((site_y_train - np.mean(site_y_train)) ** 2)\n",
    "        ss_total_test = np.sum((site_y_test - np.mean(site_y_test)) ** 2)\n",
    "        ss_residual_train = np.sum((site_y_pred_train - site_y_train) ** 2)\n",
    "        ss_residual_test = np.sum((site_y_pred_test - site_y_test) ** 2)\n",
    "\n",
    "        r2_train = 1 - (ss_residual_train / ss_total_train)\n",
    "        r2_test = 1 - (ss_residual_test / ss_total_test)\n",
    "\n",
    "        ## results\n",
    "        site_result = {'Site':site\n",
    "                    ,'MAE train':site_mae_train                   \n",
    "                    ,'MAE test':site_mae_test\n",
    "                    ,'MSE train':site_mse_train\n",
    "                    ,'MSE test':site_mse_test\n",
    "                    ,'NRMSE train':site_nrmse_train\n",
    "                    ,'NRMSE test':site_nrmse_test\n",
    "                    ,'r2 train':r2_train\n",
    "                    ,'r2 test':r2_test\n",
    "                    }\n",
    "\n",
    "        results.append(site_result)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history_dict,measure='mae'):\n",
    "    acc_values = history_dict[measure]\n",
    "    val_acc_values = history_dict[f'val_{measure}']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel(measure)\n",
    "\n",
    "    ax.plot(epochs, acc_values, color='blue', label=f'Training {measure}')\n",
    "    ax.plot(epochs, val_acc_values, color='red', label=f'Test {measure}')\n",
    "    ax.set_title(f'Training and validation {measure}')\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline accuracy is the mean of site, month, weekday, hour\n",
    "keras_calculate_baseline_accuracy(base_y_pred_train\n",
    "                                ,base_y_pred_test\n",
    "                                ,base_y_train\n",
    "                                ,base_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_calculate_accuracy(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_results = calculate_site_accuracy(df,model\n",
    "                                       , X_train\n",
    "                                       , X_test\n",
    "                                       , y_train\n",
    "                                       , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history.history,measure='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_train = model.predict(X_train).flatten()\n",
    "y_pred_test = model.predict(X_test).flatten()\n",
    "\n",
    "# Plot errors for both training and test data\n",
    "plot_prediction_error(y_train, y_pred_train, title='Training Data - Prediction Error Plot')\n",
    "plot_prediction_error(y_test, y_pred_test, title='Test Data - Prediction Error Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_train = model.predict(X_train).flatten()\n",
    "y_pred_test = model.predict(X_test).flatten()\n",
    "\n",
    "# Plot the density plots as subplots\n",
    "plot_prediction_density_subplots(y_train, y_pred_train, y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_density_subplots(base_y_train\n",
    "                                 , base_y_pred_train\n",
    "                                 , base_y_test\n",
    "                                 , base_y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downstream_111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
